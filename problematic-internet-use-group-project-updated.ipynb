{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6722358f",
   "metadata": {
    "papermill": {
     "duration": 0.003807,
     "end_time": "2024-11-28T22:01:23.512150",
     "exception": false,
     "start_time": "2024-11-28T22:01:23.508343",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "# Enhanced Data Loading and Processing\n",
    "This notebook processes datasets stored in `.parquet` format. \n",
    "Key enhancements include:\n",
    "- Robust error handling in the `process_file` function.\n",
    "- Parallelized data loading for efficiency.\n",
    "- Visualization of key patterns using heatmaps and distributions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39ddfdea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T03:55:15.732236Z",
     "iopub.status.busy": "2024-12-02T03:55:15.730812Z",
     "iopub.status.idle": "2024-12-02T03:55:17.541357Z",
     "shell.execute_reply": "2024-12-02T03:55:17.540189Z",
     "shell.execute_reply.started": "2024-12-02T03:55:15.732171Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the libraries\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pandas.plotting import andrews_curves\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc239203",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T03:55:17.544258Z",
     "iopub.status.busy": "2024-12-02T03:55:17.543716Z",
     "iopub.status.idle": "2024-12-02T03:55:17.555448Z",
     "shell.execute_reply": "2024-12-02T03:55:17.554235Z",
     "shell.execute_reply.started": "2024-12-02T03:55:17.544221Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def process_file(filename, dirname):\n",
    "    \"\"\"\n",
    "    Processes a given parquet file by loading, cleaning, and transforming it.\n",
    "    Parameters:\n",
    "        filename (str): Name of the file to process.\n",
    "        dirname (str): Directory containing the file.\n",
    "    Returns:\n",
    "        pd.DataFrame: Processed DataFrame.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        file_path = os.path.join(dirname, filename)\n",
    "        if not os.path.exists(file_path):\n",
    "            raise FileNotFoundError(f\"File {file_path} does not exist.\")\n",
    "        \n",
    "        df = pd.read_parquet(file_path)\n",
    "        \n",
    "        # Drop unnecessary columns\n",
    "        if 'step' in df.columns:\n",
    "            df.drop(columns='step', inplace=True)\n",
    "        \n",
    "        # Handle missing values using SimpleImputer\n",
    "        imputer = SimpleImputer(strategy='mean')\n",
    "        df_cleaned = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "        \n",
    "        return df_cleaned\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {filename}: {e}\")\n",
    "        return None\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4399e7b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T03:55:17.557298Z",
     "iopub.status.busy": "2024-12-02T03:55:17.556898Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 413/996 [00:42<00:46, 12.56it/s]"
     ]
    }
   ],
   "source": [
    "# CP: Load data\n",
    "\n",
    "# CP: Check if you are running in Kaggle or locally\n",
    "\n",
    "\n",
    "\n",
    "# CP: Running locally\n",
    "\n",
    "if os.path.exists(\"kaggle_data\"):\n",
    "\n",
    "    train_data = pd.read_csv(\"kaggle_data/train.csv\")\n",
    "\n",
    "    test_data = pd.read_csv(\"kaggle_data/test.csv\")\n",
    "\n",
    "    data_dict = pd.read_csv(\"kaggle_data/data_dictionary.csv\")\n",
    "\n",
    "    train_ts = load_time_series(\"kaggle_data/series_train.parquet\")\n",
    "\n",
    "    test_ts = load_time_series(\"kaggle_data/series_test.parquet\")\n",
    "\n",
    "\n",
    "\n",
    "# CP: Running in Kaggle\n",
    "\n",
    "else:\n",
    "\n",
    "    train_data = pd.read_csv(\n",
    "\n",
    "        \"/kaggle/input/child-mind-institute-problematic-internet-use/train.csv\"\n",
    "\n",
    "    )\n",
    "\n",
    "    test_data = pd.read_csv(\n",
    "\n",
    "        \"/kaggle/input/child-mind-institute-problematic-internet-use/test.csv\"\n",
    "\n",
    "    )\n",
    "\n",
    "    data_dict = pd.read_csv(\n",
    "\n",
    "        \"/kaggle/input/child-mind-institute-problematic-internet-use/data_dictionary.csv\"\n",
    "\n",
    "    )\n",
    "\n",
    "    train_ts = load_time_series(\n",
    "\n",
    "        \"/kaggle/input/child-mind-institute-problematic-internet-use/series_train.parquet\"\n",
    "\n",
    "    )\n",
    "\n",
    "    test_ts = load_time_series(\n",
    "\n",
    "        \"/kaggle/input/child-mind-institute-problematic-internet-use/series_test.parquet\"\n",
    "\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0de66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "time_series_cols = train_ts.columns.tolist()\n",
    "\n",
    "time_series_cols.remove(\"id\")\n",
    "\n",
    "train_data = pd.merge(train_data, train_ts, how=\"left\", on=\"id\")\n",
    "\n",
    "test_data = pd.merge(test_data, test_ts, how=\"left\", on=\"id\")\n",
    "\n",
    "train_data = train_data.drop(\"id\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca30d857",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 3.394442,
     "end_time": "2024-11-28T22:01:26.910156",
     "exception": false,
     "start_time": "2024-11-28T22:01:23.515714",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "column_names = list(test_data.columns)\n",
    "\n",
    "\n",
    "\n",
    "target = train_data[\"sii\"]\n",
    "\n",
    "train_data = pd.DataFrame(train_data, columns=column_names)\n",
    "\n",
    "\n",
    "\n",
    "train_data[\"sii\"] = target\n",
    "\n",
    "\n",
    "\n",
    "print(train_data.columns.difference(test_data.columns))\n",
    "\n",
    "print(train_data.shape)\n",
    "\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4026859",
   "metadata": {
    "papermill": {
     "duration": 0.003105,
     "end_time": "2024-11-28T22:01:26.916751",
     "exception": false,
     "start_time": "2024-11-28T22:01:26.913646",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453d4969",
   "metadata": {
    "papermill": {
     "duration": 0.082098,
     "end_time": "2024-11-28T22:01:27.002688",
     "exception": false,
     "start_time": "2024-11-28T22:01:26.920590",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dropping ID columns.\n",
    "\n",
    "ids = test_data[\"id\"]\n",
    "\n",
    "\n",
    "\n",
    "train_data = train_data.drop(\"id\", axis=1)\n",
    "\n",
    "test_data = test_data.drop(\"id\", axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# Using one hot encoding on the categorical data.\n",
    "\n",
    "\n",
    "train_data = pd.get_dummies(train_data)\n",
    "\n",
    "test_data = pd.get_dummies(test_data)\n",
    "\n",
    "train_data, test_data = train_data.align(test_data, join=\"outer\", axis=1)\n",
    "\n",
    "\n",
    "train_data.fillna(value=0, inplace=True)\n",
    "\n",
    "test_data.fillna(value=0, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# Imputing missing data with SimpleImputer\n",
    "\n",
    "print(train_data.shape)\n",
    "\n",
    "print(test_data.shape)\n",
    "\n",
    "\n",
    "\n",
    "print(train_data.info())\n",
    "\n",
    "print(test_data.info())\n",
    "\n",
    "\n",
    "\n",
    "difference = train_data.columns.difference(test_data.columns)\n",
    "\n",
    "print(difference)\n",
    "\n",
    "\n",
    "\n",
    "test_data = test_data.drop(columns=[\"sii\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da66290",
   "metadata": {
    "papermill": {
     "duration": 0.003356,
     "end_time": "2024-11-28T22:01:27.010406",
     "exception": false,
     "start_time": "2024-11-28T22:01:27.007050",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Random Forest Model Predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c88a0f",
   "metadata": {
    "papermill": {
     "duration": 1.197939,
     "end_time": "2024-11-28T22:01:28.211913",
     "exception": false,
     "start_time": "2024-11-28T22:01:27.013974",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "\n",
    "X = train_data.drop(columns=[\"sii\"])\n",
    "\n",
    "y = train_data[\"sii\"]\n",
    "\n",
    "\n",
    "\n",
    "# Scaling the training data.\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "\n",
    "# Splitting the training and testing data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "\n",
    "    X, y, test_size=0.1, random_state=42\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "# Initiating the random forrest model\n",
    "\n",
    "RFC = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# Fitting the model\n",
    "\n",
    "RFC.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "# Predicting test set results\n",
    "\n",
    "y_pred_test = RFC.predict(X_test)\n",
    "\n",
    "y_pred_train = RFC.predict(X_train)\n",
    "\n",
    "\n",
    "print(\n",
    "\n",
    "    \"Testing data: Model accuracy score with 100 decision-trees : {0:0.4f}\".format(\n",
    "\n",
    "        accuracy_score(y_test, y_pred_test) * 100\n",
    "\n",
    "    )\n",
    "\n",
    ")\n",
    "\n",
    "print(\n",
    "\n",
    "    \"Training data: Model accuracy score with 100 decision-trees : {0:0.4f}\".format(\n",
    "\n",
    "        accuracy_score(y_train, y_pred_train) * 100\n",
    "\n",
    "    )\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74e9924",
   "metadata": {
    "papermill": {
     "duration": 0.003386,
     "end_time": "2024-11-28T22:01:28.219309",
     "exception": false,
     "start_time": "2024-11-28T22:01:28.215923",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Logistic Regression Model Predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e63b1f0",
   "metadata": {
    "papermill": {
     "duration": 0.402475,
     "end_time": "2024-11-28T22:01:28.625532",
     "exception": false,
     "start_time": "2024-11-28T22:01:28.223057",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "\n",
    "X = train_data.drop(columns=[\"sii\"])\n",
    "\n",
    "y = train_data[\"sii\"]\n",
    "\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "\n",
    "    X, y, test_size=0.1, random_state=42\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "LR = LogisticRegression()\n",
    "\n",
    "\n",
    "\n",
    "LR.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "y_pred_test = LR.predict(X_test)\n",
    "\n",
    "y_pred_train = RFC.predict(X_train)\n",
    "\n",
    "\n",
    "\n",
    "print(\n",
    "\n",
    "    \"Testing data accuracy: {0:0.4f}\".format(accuracy_score(y_test, y_pred_test) * 100)\n",
    "\n",
    ")\n",
    "\n",
    "print(\n",
    "\n",
    "    \"Training data accuracy: {0:0.4f}\".format(\n",
    "\n",
    "        accuracy_score(y_train, y_pred_train) * 100\n",
    "\n",
    "    )\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405bc686",
   "metadata": {
    "papermill": {
     "duration": 0.003823,
     "end_time": "2024-11-28T22:01:28.633308",
     "exception": false,
     "start_time": "2024-11-28T22:01:28.629485",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Random Forest Predictions On Test Set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1914674",
   "metadata": {
    "papermill": {
     "duration": 0.011511,
     "end_time": "2024-11-28T22:01:28.648607",
     "exception": false,
     "start_time": "2024-11-28T22:01:28.637096",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# X = test_data\n",
    "\n",
    "# X = scaler.fit_transform(X)\n",
    "\n",
    "# y_pred = RFC.predict(X)\n",
    "\n",
    "# Predict on test data\n",
    "\n",
    "\n",
    "\n",
    "# Creating submission file\n",
    "\n",
    "# submission = pd.DataFrame({\n",
    "\n",
    "#   'id': ids,\n",
    "\n",
    "#   'sii': y_pred.astype(int)\n",
    "\n",
    "# })\n",
    "\n",
    "# print(submission)\n",
    "\n",
    "\n",
    "\n",
    "# save to CSV\n",
    "\n",
    "# submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "# print(\"Submission file created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b03c64f",
   "metadata": {
    "papermill": {
     "duration": 0.004442,
     "end_time": "2024-11-28T22:01:28.656849",
     "exception": false,
     "start_time": "2024-11-28T22:01:28.652407",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Logistic Regression Predictions On Test Set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9a4b63",
   "metadata": {
    "papermill": {
     "duration": 0.026177,
     "end_time": "2024-11-28T22:01:28.686675",
     "exception": false,
     "start_time": "2024-11-28T22:01:28.660498",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Predicting on test data\n",
    "\n",
    "X = test_data\n",
    "\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "y_pred = LR.predict(X)\n",
    "\n",
    "\n",
    "submission = pd.DataFrame({\"id\": ids, \"sii\": y_pred.astype(int)})\n",
    "\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "print(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98d341d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if processed_dataframes:\n",
    "    combined_df = pd.concat(processed_dataframes, ignore_index=True)\n",
    "    print(\"Data Summary:\")\n",
    "    print(combined_df.describe())\n",
    "    \n",
    "    # Visualization: Correlation heatmap\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(combined_df.corr(), annot=True, cmap=\"coolwarm\")\n",
    "    plt.title(\"Correlation Heatmap\")\n",
    "    plt.show()\n",
    "\n",
    "    # Visualization: Distribution of a key variable\n",
    "    if \"CGAS-CGAS_Score\" in combined_df.columns:\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        sns.histplot(combined_df[\"CGAS-CGAS_Score\"], bins=30, kde=True)\n",
    "        plt.title(\"Distribution of CGAS Scores\")\n",
    "        plt.xlabel(\"CGAS Score\")\n",
    "        plt.ylabel(\"Frequency\")\n",
    "        plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 9643020,
     "sourceId": 81933,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8.795735,
   "end_time": "2024-11-28T22:01:29.420849",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-28T22:01:20.625114",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
