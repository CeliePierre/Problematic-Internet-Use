{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92349618",
   "metadata": {
    "papermill": {
     "duration": 0.003807,
     "end_time": "2024-11-28T22:01:23.512150",
     "exception": false,
     "start_time": "2024-11-28T22:01:23.508343",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Loading The Data Sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdf61ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import andrews_curves\n",
    "from sklearn.impute import SimpleImputer\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72f9044e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CP: Processes a parquet file\n",
    "# Cite: https://www.kaggle.com/code/cchangyyy/0-490-notebook\n",
    "\n",
    "\n",
    "def process_file(filename, dirname):\n",
    "    df = pd.read_parquet(os.path.join(dirname, filename, \"part-0.parquet\"))\n",
    "    df.drop(\"step\", axis=1, inplace=True)\n",
    "    return df.describe().values.reshape(-1), filename.split(\"=\")[1]\n",
    "\n",
    "\n",
    "def load_time_series(dirname) -> pd.DataFrame:\n",
    "    ids = os.listdir(dirname)\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        results = list(\n",
    "            tqdm(\n",
    "                executor.map(lambda fname: process_file(fname, dirname), ids),\n",
    "                total=len(ids),\n",
    "            )\n",
    "        )\n",
    "    stats, indexes = zip(*results)\n",
    "    df = pd.DataFrame(stats, columns=[f\"stat_{i}\" for i in range(len(stats[0]))])\n",
    "    df[\"id\"] = indexes\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4713b4a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 996/996 [00:30<00:00, 32.97it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 18.85it/s]\n"
     ]
    }
   ],
   "source": [
    "# CP: Load data\n",
    "# CP: Check if you are running in Kaggle or locally\n",
    "\n",
    "# CP: Running locally\n",
    "if os.path.exists(\"kaggle_data\"):\n",
    "    train_data = pd.read_csv(\"kaggle_data/train.csv\")\n",
    "    test_data = pd.read_csv(\"kaggle_data/test.csv\")\n",
    "    data_dict = pd.read_csv(\"kaggle_data/data_dictionary.csv\")\n",
    "    train_ts = load_time_series(\"kaggle_data/series_train.parquet\")\n",
    "    test_ts = load_time_series(\"kaggle_data/series_test.parquet\")\n",
    "\n",
    "# CP: Running in Kaggle\n",
    "else:\n",
    "    train_data = pd.read_csv(\n",
    "        \"/kaggle/input/child-mind-institute-problematic-internet-use/train.csv\"\n",
    "    )\n",
    "    test_data = pd.read_csv(\n",
    "        \"/kaggle/input/child-mind-institute-problematic-internet-use/test.csv\"\n",
    "    )\n",
    "    data_dict = pd.read_csv(\n",
    "        \"/kaggle/input/child-mind-institute-problematic-internet-use/data_dictionary.csv\"\n",
    "    )\n",
    "    train_ts = load_time_series(\n",
    "        \"/kaggle/input/child-mind-institute-problematic-internet-use/series_train.parquet\"\n",
    "    )\n",
    "    test_ts = load_time_series(\n",
    "        \"/kaggle/input/child-mind-institute-problematic-internet-use/series_test.parquet\"\n",
    "    )\n",
    "\n",
    "column_names = list(test_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e6093ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cite: https://www.kaggle.com/code/cchangyyy/0-490-notebook\n",
    "\n",
    "time_series_cols = train_ts.columns.tolist()\n",
    "time_series_cols.remove(\"id\")\n",
    "train_data = pd.merge(train_data, train_ts, how=\"left\", on=\"id\")\n",
    "test_data = pd.merge(test_data, test_ts, how=\"left\", on=\"id\")\n",
    "train_data = train_data.drop(\"id\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db2b2752",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-28T22:01:23.523130Z",
     "iopub.status.busy": "2024-11-28T22:01:23.522505Z",
     "iopub.status.idle": "2024-11-28T22:01:26.907301Z",
     "shell.execute_reply": "2024-11-28T22:01:26.905685Z"
    },
    "papermill": {
     "duration": 3.394442,
     "end_time": "2024-11-28T22:01:26.910156",
     "exception": false,
     "start_time": "2024-11-28T22:01:23.515714",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['sii'], dtype='object')\n",
      "(3960, 60)\n",
      "(20, 155)\n"
     ]
    }
   ],
   "source": [
    "# Dropping all columns that have less than 2000 examples.\n",
    "\n",
    "target = train_data[\"sii\"]\n",
    "train_data = pd.DataFrame(train_data, columns=column_names)\n",
    "\n",
    "train_data[\"sii\"] = target\n",
    "\n",
    "print(train_data.columns.difference(test_data.columns))\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3b3676",
   "metadata": {
    "papermill": {
     "duration": 0.003105,
     "end_time": "2024-11-28T22:01:26.916751",
     "exception": false,
     "start_time": "2024-11-28T22:01:26.913646",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5ee1d05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T22:01:26.925978Z",
     "iopub.status.busy": "2024-11-28T22:01:26.925560Z",
     "iopub.status.idle": "2024-11-28T22:01:26.999117Z",
     "shell.execute_reply": "2024-11-28T22:01:26.997865Z"
    },
    "papermill": {
     "duration": 0.082098,
     "end_time": "2024-11-28T22:01:27.002688",
     "exception": false,
     "start_time": "2024-11-28T22:01:26.920590",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3960, 185)\n",
      "(20, 185)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3960 entries, 0 to 3959\n",
      "Columns: 185 entries, BIA-BIA_Activity_Level_num to stat_95\n",
      "dtypes: bool(40), float64(143), int64(2)\n",
      "memory usage: 4.5 MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20 entries, 0 to 19\n",
      "Columns: 185 entries, BIA-BIA_Activity_Level_num to stat_95\n",
      "dtypes: bool(35), float64(148), int64(2)\n",
      "memory usage: 24.2 KB\n",
      "None\n",
      "Index([], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Dropping ID columns.\n",
    "# Saving ID column for Kaggle prediction.\n",
    "ids = test_data[\"id\"]\n",
    "\n",
    "train_data = train_data.drop(\"id\", axis=1)\n",
    "test_data = test_data.drop(\"id\", axis=1)\n",
    "\n",
    "# Using one hot encoding on the categorical data.\n",
    "# Cite: https://stackoverflow.com/questions/41973423/typeerror-dataframe-object-is-not-callable\n",
    "# Cite: https://www.kaggle.com/code/dansbecker/using-categorical-data-with-one-hot-encoding\n",
    "train_data = pd.get_dummies(train_data)\n",
    "test_data = pd.get_dummies(test_data)\n",
    "train_data, test_data = train_data.align(test_data, join=\"outer\", axis=1)\n",
    "\n",
    "# mean = train_data.mean()\n",
    "# Cite: https://www.kaggle.com/code/dansbecker/handling-missing-values\n",
    "train_data.fillna(value=0, inplace=True)\n",
    "test_data.fillna(value=0, inplace=True)\n",
    "\n",
    "# Imputing missing data with SimpleImputer\n",
    "# imputer = SimpleImputer()\n",
    "# imputed_data = imputer.fit_transform(train_data)\n",
    "# train_data = pd.DataFrame(imputed_data, columns=train_data.columns)\n",
    "\n",
    "\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "\n",
    "print(train_data.info())\n",
    "print(test_data.info())\n",
    "\n",
    "difference = train_data.columns.difference(test_data.columns)\n",
    "print(difference)\n",
    "\n",
    "test_data = test_data.drop(columns=[\"sii\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3baab500",
   "metadata": {
    "papermill": {
     "duration": 0.003356,
     "end_time": "2024-11-28T22:01:27.010406",
     "exception": false,
     "start_time": "2024-11-28T22:01:27.007050",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Random Forest Model Predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1061ce69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T22:01:27.020582Z",
     "iopub.status.busy": "2024-11-28T22:01:27.019993Z",
     "iopub.status.idle": "2024-11-28T22:01:28.208936Z",
     "shell.execute_reply": "2024-11-28T22:01:28.207860Z"
    },
    "papermill": {
     "duration": 1.197939,
     "end_time": "2024-11-28T22:01:28.211913",
     "exception": false,
     "start_time": "2024-11-28T22:01:27.013974",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing data: Model accuracy score with 100 decision-trees : 71.9697\n",
      "Training data: Model accuracy score with 100 decision-trees : 100.0000\n"
     ]
    }
   ],
   "source": [
    "# Cite: https://www.kaggle.com/code/prashant111/random-forest-classifier-tutorial\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "X = train_data.drop(columns=[\"sii\"])\n",
    "y = train_data[\"sii\"]\n",
    "\n",
    "# Scaling the training data.\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Splitting the training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.1, random_state=42\n",
    ")\n",
    "\n",
    "# Initiating the random forrest model\n",
    "RFC = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fitting the model\n",
    "RFC.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Predicting test set results\n",
    "y_pred_test = RFC.predict(X_test)\n",
    "y_pred_train = RFC.predict(X_train)\n",
    "\n",
    "# Checking accuracy score\n",
    "print(\n",
    "    \"Testing data: Model accuracy score with 100 decision-trees : {0:0.4f}\".format(\n",
    "        accuracy_score(y_test, y_pred_test) * 100\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"Training data: Model accuracy score with 100 decision-trees : {0:0.4f}\".format(\n",
    "        accuracy_score(y_train, y_pred_train) * 100\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4c658c",
   "metadata": {
    "papermill": {
     "duration": 0.003386,
     "end_time": "2024-11-28T22:01:28.219309",
     "exception": false,
     "start_time": "2024-11-28T22:01:28.215923",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Logistic Regression Model Predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b130ab80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T22:01:28.228328Z",
     "iopub.status.busy": "2024-11-28T22:01:28.227921Z",
     "iopub.status.idle": "2024-11-28T22:01:28.622482Z",
     "shell.execute_reply": "2024-11-28T22:01:28.619576Z"
    },
    "papermill": {
     "duration": 0.402475,
     "end_time": "2024-11-28T22:01:28.625532",
     "exception": false,
     "start_time": "2024-11-28T22:01:28.223057",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing data accuracy: 72.4747\n",
      "Training data accuracy: 100.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X = train_data.drop(columns=[\"sii\"])\n",
    "y = train_data[\"sii\"]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.1, random_state=42\n",
    ")\n",
    "\n",
    "LR = LogisticRegression()\n",
    "\n",
    "LR.fit(X_train, y_train)\n",
    "\n",
    "y_pred_test = LR.predict(X_test)\n",
    "y_pred_train = RFC.predict(X_train)\n",
    "\n",
    "print(\n",
    "    \"Testing data accuracy: {0:0.4f}\".format(accuracy_score(y_test, y_pred_test) * 100)\n",
    ")\n",
    "print(\n",
    "    \"Training data accuracy: {0:0.4f}\".format(\n",
    "        accuracy_score(y_train, y_pred_train) * 100\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d3dea3",
   "metadata": {
    "papermill": {
     "duration": 0.003823,
     "end_time": "2024-11-28T22:01:28.633308",
     "exception": false,
     "start_time": "2024-11-28T22:01:28.629485",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Random Forest Predictions On Test Set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "227d3e73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T22:01:28.642417Z",
     "iopub.status.busy": "2024-11-28T22:01:28.642005Z",
     "iopub.status.idle": "2024-11-28T22:01:28.646581Z",
     "shell.execute_reply": "2024-11-28T22:01:28.645468Z"
    },
    "papermill": {
     "duration": 0.011511,
     "end_time": "2024-11-28T22:01:28.648607",
     "exception": false,
     "start_time": "2024-11-28T22:01:28.637096",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# X = test_data\n",
    "# X = scaler.fit_transform(X)\n",
    "# y_pred = RFC.predict(X)\n",
    "# Predict on test data\n",
    "\n",
    "# Creating submission file\n",
    "# submission = pd.DataFrame({\n",
    "#   'id': ids,\n",
    "#   'sii': y_pred.astype(int)\n",
    "# })\n",
    "# print(submission)\n",
    "\n",
    "# save to CSV\n",
    "# submission.to_csv('submission.csv', index=False)\n",
    "# print(\"Submission file created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db335d2",
   "metadata": {
    "papermill": {
     "duration": 0.004442,
     "end_time": "2024-11-28T22:01:28.656849",
     "exception": false,
     "start_time": "2024-11-28T22:01:28.652407",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Logistic Regression Predictions On Test Set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5240b8b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T22:01:28.665736Z",
     "iopub.status.busy": "2024-11-28T22:01:28.665348Z",
     "iopub.status.idle": "2024-11-28T22:01:28.684539Z",
     "shell.execute_reply": "2024-11-28T22:01:28.683161Z"
    },
    "papermill": {
     "duration": 0.026177,
     "end_time": "2024-11-28T22:01:28.686675",
     "exception": false,
     "start_time": "2024-11-28T22:01:28.660498",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id  sii\n",
      "0   00008ff9    0\n",
      "1   000fd460    0\n",
      "2   00105258    2\n",
      "3   00115b9f    0\n",
      "4   0016bb22    0\n",
      "5   001f3379    0\n",
      "6   0038ba98    2\n",
      "7   0068a485    0\n",
      "8   0069fbed    0\n",
      "9   0083e397    0\n",
      "10  0087dd65    0\n",
      "11  00abe655    2\n",
      "12  00ae59c9    3\n",
      "13  00af6387    0\n",
      "14  00bd4359    0\n",
      "15  00c0cd71    1\n",
      "16  00d56d4b    0\n",
      "17  00d9913d    0\n",
      "18  00e6167c    0\n",
      "19  00ebc35d    0\n"
     ]
    }
   ],
   "source": [
    "# Predicting on test data\n",
    "X = test_data\n",
    "X = scaler.fit_transform(X)\n",
    "y_pred = LR.predict(X)\n",
    "\n",
    "# Creating the submission file\n",
    "submission = pd.DataFrame({\"id\": ids, \"sii\": y_pred.astype(int)})\n",
    "\n",
    "# saving to CSV\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "print(submission)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf80fdae",
   "metadata": {
    "papermill": {
     "duration": 0.003653,
     "end_time": "2024-11-28T22:01:28.694306",
     "exception": false,
     "start_time": "2024-11-28T22:01:28.690653",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "For both models, I split the training and testing data 90/10 with random_state set to 42.\n",
    "\n",
    "Random Forrest Classifier Peramters: n_estimators=100, \\*, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='sqrt', max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None, monotonic_cst=None\n",
    "\n",
    "Logistic Regression Parameters: penalty='l2', \\*, dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=100, multi_class='deprecated', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None\n",
    "\n",
    "After I receive my results from Kaggle, I'm expecting to get around 74% accuracy on the RFC model, and 72% accuracy on the LR model. I got these estimates from the two model performance results on the train/test split data that I printed.\n",
    "\n",
    "The accuracy scores I received from Kaggle on the test set they provided were 27% for the Logistic Regression model and 17% accuracy for the Random Forrest classifier model. When comparing these scores to the LR 72% and RFC 74% scores from my training set, it's clear that both models are overfitting the data, have low bias, and have high variance.\n",
    "\n",
    "The performance of my models shows that they both overfit the data and need to be generalized more. I plan to improve this accuracy in a couple of areas. First I will change the way I handle missing data by instead of replacing missing data points with 0s, I will replace them with the mean of that column. I will also improve my data's regularization and make the models more generalized by removing features that don't correlate too well with the data. I also plan on tuning my parameters and experimenting with which ones affect model performance. Additionally, I may experiment with running cross-validation on the training data to help further prevent overfitting.\n",
    "\n",
    "My biggest takeaway from this assignment is that preprocessing is the most crucial and important part of creating an accurate machine-learning model. It doesn't matter how well-prepared my model or parameters are, if I don't have clean data, I won't get accurate predictions. I learned while doing this assignment that the more steps I take to preprocess and clean up my datasets, the more accurate my models are.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1a7240",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 9643020,
     "sourceId": 81933,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8.795735,
   "end_time": "2024-11-28T22:01:29.420849",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-28T22:01:20.625114",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
